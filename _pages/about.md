---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a third-year PhD student at Pennsylvania State University. I am fortunate to be advised by [Dr. Jinyuan Jia](https://jinyuan-jia.github.io/). My research focuses on AI Security & Trustworthy ML, recently focusing on LLM robustness and transparency. Previously, I earned double bachelorâ€™s degrees in Mechanical Engineering and Computer Science from RPI, followed by a masterâ€™s in Computer Science from Duke University.

## Current research focuses
* Transparency of LLM-empowered AI systems for security purposes
* Enhancing the efficiency of optimization-based LLM red-teaming
* Provably secure/robust machine learning systems

## Publications

*\* Equal contribution*
* **\*Yanting Wang**,  \*Wei Zou, Runpeng Geng, and Jinyuan Jia. [TracLLM: A Generic Framework for Attributing Long Context LLMs](https://arxiv.org/abs/2506.04202), In *USENIX Security*, 2025. ðŸ”— [Code](https://github.com/Wang-Yanting/TracLLM)
* Yupei Liu, **Yanting Wang**, and Jinyuan Jia. [TrojanDec: Data-free Detection of Trojan Inputs in Self-supervised Learning](https://arxiv.org/pdf/2501.04108), In *AAAI*, 2025.
* **Yanting Wang**, Wei Zou, Jinyuan Jia. [FCert: Certifiably Robust Few-Shot Classification in the Era of Foundation Models](https://arxiv.org/pdf/2404.08631), In *IEEE S&P*, 2024. ðŸ”— [Code](https://github.com/Wang-Yanting/FCert) 
* **Yanting Wang**, Hongye Fu, Wei Zou, and Jinyuan Jia. [MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models](https://arxiv.org/abs/2403.19080), In *CVPR*, 2024. ðŸ”— [Code](https://github.com/Wang-Yanting/MMCert)

## Preprints
* **Yanting Wang**, Runpeng Geng, Jinghui Chen, Minhao Cheng, Jinyuan Jia.  
  [TASO: Jailbreak LLMs via Alternative Template and Suffix Optimization](https://www.alphaxiv.org/abs/2511.18581), In arXiv, 2025.
* Runpeng Geng, **Yanting Wang**, Chenlong Yin, Minhao Cheng, Ying Chen, Jinyuan Jia.
  [PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization](https://arxiv.org/pdf/2511.10720v1), In arXiv, 2025. ðŸ”— [Code](https://github.com/sleeepeer/PISanitizer)
* Wei Zou, Yupei Liu, **Yanting Wang**, Ying Chen, Neil Gong, and Jinyuan Jia.  
  [PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](https://arxiv.org/abs/2510.14005), In arXiv, 2025. ðŸ”— [Code](https://github.com/weizou52/PIShield)
* Runpeng Geng, **Yanting Wang**, Ying Chen, and Jinyuan Jia.  
  [UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation](https://arxiv.org/abs/2508.18652), In arXiv, 2025.
* Yupei Liu, **Yanting Wang**, Yuqi Jia, Jinyuan Jia, and Neil Zhenqiang Gong.  
  [SecInfer: Preventing Prompt Injection via Inference-Time Scaling](https://arxiv.org/abs/2509.24967), In arXiv, 2025.
* Yanting Wang, Runpeng Geng, Ying Chen, and Jinyuan Jia. [AttnTrace: Attention-based Context Traceback for Long-Context LLMs](https://arxiv.org/html/2508.03793v1), In arxiv, 2025. ðŸ”— [Code](https://github.com/Wang-Yanting/AttnTrace) [Demo (HF Spaces)](https://huggingface.co/spaces/SecureLLMSys/AttnTrace)
* Yuzhou Nie, **Yanting Wang**, Jinyuan Jia, Michael J. De Lucia, Nathaniel D. Bastian, Wenbo Guo, and Dawn Song. [TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models](https://arxiv.org/abs/2405.16783), In arxiv, 2024.

## Professional Service
### Program Committee member:
AAAI, 2026
### Reviewer:
Pattern Recognition, 2025  
TNNLS, 2024
## Personal 
Iâ€™m always interested in trying new things. Outside of work, I enjoy playing all kinds of ball sports, hiking, and snowboarding.
